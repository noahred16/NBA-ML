{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.11 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.11 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "%pip install numpy\n",
    "%pip install scikit-learn\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize and assign the data to classes to load in batches for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Quick normalization first\n",
    "def quick_normalize(game_objects):\n",
    "    print(\"Starting quick normalization...\")\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # Collect all data to fit the scaler\n",
    "    print(\"Collecting all data to fit scaler...\")\n",
    "    all_data = []\n",
    "    for game in game_objects:\n",
    "        all_data.append(game.matchups)\n",
    "        all_data.append(game.team_history)\n",
    "        all_data.append(game.opponent_history)\n",
    "    \n",
    "    # Concatenate all data and fit the scaler\n",
    "    print(\"Fitting scaler...\")\n",
    "    combined_data = pd.concat(all_data)\n",
    "    scaler.fit(combined_data)\n",
    "    \n",
    "    # Now transform each game's data using the fitted scaler\n",
    "    print(\"Transforming data...\")\n",
    "    for i, game in enumerate(game_objects):\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Normalizing game {i}/{len(game_objects)}\")\n",
    "            \n",
    "        # Normalize game_date\n",
    "        baseline_date = pd.to_datetime(\"2000-01-01\")\n",
    "        game.game_date = (pd.to_datetime(game.game_date) - baseline_date).days\n",
    "        \n",
    "        # Transform each sequence using the same scaler\n",
    "        game.matchups = pd.DataFrame(\n",
    "            scaler.transform(game.matchups),\n",
    "            columns=game.matchups.columns,\n",
    "            index=game.matchups.index\n",
    "        )\n",
    "        game.team_history = pd.DataFrame(\n",
    "            scaler.transform(game.team_history),\n",
    "            columns=game.team_history.columns,\n",
    "            index=game.team_history.index\n",
    "        )\n",
    "        game.opponent_history = pd.DataFrame(\n",
    "            scaler.transform(game.opponent_history),\n",
    "            columns=game.opponent_history.columns,\n",
    "            index=game.opponent_history.index\n",
    "        )\n",
    "    \n",
    "    return game_objects, scaler\n",
    "\n",
    "# Classes for PyTorch handling\n",
    "class GameData:\n",
    "    def __init__(self, game_id, game_date, is_regular_season, is_playoffs, \n",
    "                 is_pre_season, matchups, team_history, opponent_history, target):\n",
    "        self.game_id = game_id\n",
    "        self.game_date = game_date\n",
    "        self.is_regular_season = is_regular_season\n",
    "        self.is_playoffs = is_playoffs\n",
    "        self.is_pre_season = is_pre_season\n",
    "        self.matchups = matchups\n",
    "        self.team_history = team_history\n",
    "        self.opponent_history = opponent_history\n",
    "        self.target = target\n",
    "\n",
    "    def to_tensor_dict(self):\n",
    "        tensor_dict = {\n",
    "            'matchups_tensor': torch.FloatTensor(self.matchups.values),\n",
    "            'team_history_tensor': torch.FloatTensor(self.team_history.values),\n",
    "            'opponent_history_tensor': torch.FloatTensor(self.opponent_history.values),\n",
    "            'matchups_lengths': torch.LongTensor([len(self.matchups)]),\n",
    "            'team_history_lengths': torch.LongTensor([len(self.team_history)]),\n",
    "            'opponent_history_lengths': torch.LongTensor([len(self.opponent_history)]),\n",
    "            'target': torch.FloatTensor([self.target]),\n",
    "            'game_type': torch.FloatTensor([\n",
    "                self.is_regular_season,\n",
    "                self.is_playoffs,\n",
    "                self.is_pre_season\n",
    "            ])\n",
    "        }\n",
    "        return tensor_dict\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_batch(batch):\n",
    "        tensor_dicts = [game.to_tensor_dict() for game in batch]\n",
    "        batch_dict = {}\n",
    "        \n",
    "        # No need for lengths or padding since sequences are fixed length\n",
    "        for key in ['matchups_tensor', 'team_history_tensor', 'opponent_history_tensor']:\n",
    "            batch_dict[key] = torch.stack([d[key] for d in tensor_dicts])\n",
    "        \n",
    "        batch_dict['game_type'] = torch.stack([d['game_type'] for d in tensor_dicts])\n",
    "        batch_dict['target'] = torch.cat([d['target'] for d in tensor_dicts])\n",
    "        \n",
    "        return batch_dict\n",
    "\n",
    "class NBAGamesDataset(Dataset):\n",
    "    def __init__(self, game_objects):\n",
    "        self.game_objects = game_objects\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.game_objects)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.game_objects[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the data and save to pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting quick normalization...\n",
      "Collecting all data to fit scaler...\n",
      "Fitting scaler...\n",
      "Transforming data...\n",
      "Normalizing game 0/28803\n",
      "Normalizing game 1000/28803\n",
      "Normalizing game 2000/28803\n",
      "Normalizing game 3000/28803\n",
      "Normalizing game 4000/28803\n",
      "Normalizing game 5000/28803\n",
      "Normalizing game 6000/28803\n",
      "Normalizing game 7000/28803\n",
      "Normalizing game 8000/28803\n",
      "Normalizing game 9000/28803\n",
      "Normalizing game 10000/28803\n",
      "Normalizing game 11000/28803\n",
      "Normalizing game 12000/28803\n",
      "Normalizing game 13000/28803\n",
      "Normalizing game 14000/28803\n",
      "Normalizing game 15000/28803\n",
      "Normalizing game 16000/28803\n",
      "Normalizing game 17000/28803\n",
      "Normalizing game 18000/28803\n",
      "Normalizing game 19000/28803\n",
      "Normalizing game 20000/28803\n",
      "Normalizing game 21000/28803\n",
      "Normalizing game 22000/28803\n",
      "Normalizing game 23000/28803\n",
      "Normalizing game 24000/28803\n",
      "Normalizing game 25000/28803\n",
      "Normalizing game 26000/28803\n",
      "Normalizing game 27000/28803\n",
      "Normalizing game 28000/28803\n",
      "\n",
      "Number of training batches: 721\n",
      "Number of validation batches: 90\n",
      "Number of test batches: 91\n"
     ]
    }
   ],
   "source": [
    "with open('rnn_game_objects.pkl', 'rb') as f:\n",
    "    game_objects = pickle.load(f)\n",
    "\n",
    "# Quick normalize\n",
    "normalized_games, scaler = quick_normalize(game_objects)\n",
    "\n",
    "# Split into train test and validation\n",
    "baseline_date = pd.to_datetime(\"2000-01-01\")\n",
    "\n",
    "train_games = []\n",
    "val_games = []\n",
    "test_games = []\n",
    "\n",
    "for game in normalized_games:\n",
    "    # Convert days since baseline back to a date\n",
    "    game_date = baseline_date + pd.Timedelta(days=int(game.game_date))\n",
    "    \n",
    "    if game_date.year <= 2019: \n",
    "        train_games.append(game)\n",
    "    elif game_date.year == 2020:  \n",
    "        val_games.append(game)\n",
    "    else:  \n",
    "        test_games.append(game)\n",
    "\n",
    "print(f\"Training games (2001-2019): {len(train_games)}\")\n",
    "print(f\"Validation games (2020): {len(val_games)}\")\n",
    "print(f\"Test games (2021-2023): {len(test_games)}\")\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "batch_size = 32\n",
    "train_dataset = NBAGamesDataset(train_games)\n",
    "val_dataset = NBAGamesDataset(val_games)\n",
    "test_dataset = NBAGamesDataset(test_games)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=GameData.collate_batch\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=GameData.collate_batch\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=GameData.collate_batch\n",
    ")\n",
    "\n",
    "# Save everything\n",
    "with open('game_stats_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "processed_data = {\n",
    "    'train_dataset': train_loader.dataset.game_objects,\n",
    "    'val_dataset': val_loader.dataset.game_objects,\n",
    "    'test_dataset': test_loader.dataset.game_objects\n",
    "}\n",
    "\n",
    "with open('processed_game_objects.pkl', 'wb') as f:\n",
    "    pickle.dump(processed_data, f)\n",
    "\n",
    "# Print information\n",
    "print(f\"\\nNumber of training batches: {len(train_loader)}\")\n",
    "print(f\"Number of validation batches: {len(val_loader)}\")\n",
    "print(f\"Number of test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model architecture for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PredictorRNN(nn.Module):\n",
    "    def __init__(self, feature_names, hidden_size=128, num_layers=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.feature_names = feature_names\n",
    "        self.input_size = len(feature_names)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # LSTM networks for each sequence type\n",
    "        self.matchups_lstm = nn.LSTM(\n",
    "            input_size=self.input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        \n",
    "        self.team_history_lstm = nn.LSTM(\n",
    "            input_size=self.input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        \n",
    "        self.opponent_history_lstm = nn.LSTM(\n",
    "            input_size=self.input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        \n",
    "        # Game type embedding\n",
    "        self.game_type_proj = nn.Linear(3, hidden_size)\n",
    "        \n",
    "        # Combination layer\n",
    "        combined_size = (hidden_size * 3) + hidden_size  \n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(combined_size, hidden_size * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, batch_dict):\n",
    "        # Process matchups (always length 5)\n",
    "        _, (matchups_hidden, _) = self.matchups_lstm(batch_dict['matchups_tensor'])\n",
    "        matchups_hidden = matchups_hidden[-1] \n",
    "        \n",
    "        # Process team history (always length 10)\n",
    "        _, (team_hidden, _) = self.team_history_lstm(batch_dict['team_history_tensor'])\n",
    "        team_hidden = team_hidden[-1]\n",
    "        \n",
    "        # Process opponent history (always length 10)\n",
    "        _, (opponent_hidden, _) = self.opponent_history_lstm(batch_dict['opponent_history_tensor'])\n",
    "        opponent_hidden = opponent_hidden[-1]\n",
    "        \n",
    "        # Process game type\n",
    "        game_type_embedded = self.game_type_proj(batch_dict['game_type'])\n",
    "        \n",
    "        # Combine all features\n",
    "        combined = torch.cat([\n",
    "            matchups_hidden,\n",
    "            team_hidden,\n",
    "            opponent_hidden,\n",
    "            game_type_embedded\n",
    "        ], dim=1)\n",
    "        \n",
    "        # Make prediction and ensure output is between 0 and 1\n",
    "        output = self.classifier(combined)\n",
    "        output = torch.clamp(output, 0, 1)  \n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def train_model(self, train_loader, val_loader, num_epochs=50, learning_rate=0.0005, patience=5):\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5)\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_model = None\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            # Training phase\n",
    "            self.train()\n",
    "            total_train_loss = 0\n",
    "            correct_predictions = 0\n",
    "            total_predictions = 0\n",
    "            \n",
    "            for batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(batch)\n",
    "                # Reshape target to match output shape\n",
    "                target = batch['target'].view(-1, 1) \n",
    "                loss = criterion(outputs, target)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_train_loss += loss.item()\n",
    "                predictions = (outputs >= 0.5).float()\n",
    "                correct_predictions += (predictions == target).sum().item()  \n",
    "                total_predictions += target.size(0)\n",
    "            \n",
    "            avg_train_loss = total_train_loss / len(train_loader)\n",
    "            train_accuracy = correct_predictions / total_predictions\n",
    "            \n",
    "            # Validation phase\n",
    "            self.eval()\n",
    "            total_val_loss = 0\n",
    "            correct_val_predictions = 0\n",
    "            total_val_predictions = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    outputs = self(batch)\n",
    "                    target = batch['target'].view(-1, 1) \n",
    "                    loss = criterion(outputs, target)\n",
    "                    \n",
    "                    total_val_loss += loss.item()\n",
    "                    predictions = (outputs >= 0.5).float()\n",
    "                    correct_val_predictions += (predictions == target).sum().item() \n",
    "                    total_val_predictions += target.size(0)\n",
    "            \n",
    "            avg_val_loss = total_val_loss / len(val_loader)\n",
    "            val_accuracy = correct_val_predictions / total_val_predictions\n",
    "            \n",
    "            scheduler.step(avg_val_loss)\n",
    "            \n",
    "            # Early stopping if val loss isn't less than best\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                best_model = self.state_dict().copy()\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                \n",
    "            print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "            print(f'Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "            print(f'Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "            print(f'Patience Counter: {patience_counter}/{patience}')\n",
    "            print('--------------------')\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                print(f'Early stopping triggered after epoch {epoch+1}')\n",
    "                break\n",
    "        \n",
    "        self.load_state_dict(best_model)\n",
    "        return self, {\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'epochs_trained': epoch + 1\n",
    "        }\n",
    "\n",
    "def create_feature_filtered_loader(original_loader, feature_names, batch_size):\n",
    "    filtered_games = []\n",
    "\n",
    "    for game in original_loader.dataset.game_objects:\n",
    "        # Check for NaN values in all sequences\n",
    "        has_nan = (game.matchups[feature_names].isna().any().any() or \n",
    "                  game.team_history[feature_names].isna().any().any() or \n",
    "                  game.opponent_history[feature_names].isna().any().any())\n",
    "        \n",
    "        if not has_nan:  # Only include games without NaN values\n",
    "            filtered_game = GameData(\n",
    "                game_id=game.game_id,\n",
    "                game_date=game.game_date,\n",
    "                is_regular_season=game.is_regular_season,\n",
    "                is_playoffs=game.is_playoffs,\n",
    "                is_pre_season=game.is_pre_season,\n",
    "                matchups=game.matchups[feature_names],\n",
    "                team_history=game.team_history[feature_names],\n",
    "                opponent_history=game.opponent_history[feature_names],\n",
    "                target=game.target\n",
    "            )\n",
    "            filtered_games.append(filtered_game)\n",
    "    \n",
    "    print(f\"Filtered out {len(original_loader.dataset.game_objects) - len(filtered_games)} games with NaN values\")\n",
    "    print(f\"Remaining games: {len(filtered_games)}\")\n",
    "\n",
    "    filtered_dataset = NBAGamesDataset(filtered_games)\n",
    "\n",
    "    return DataLoader(\n",
    "        filtered_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True if original_loader.dataset == 'train' else False,\n",
    "        collate_fn=GameData.collate_batch\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model and check accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 10 games with NaN values\n",
      "Remaining games: 23032\n",
      "Filtered out 0 games with NaN values\n",
      "Remaining games: 2880\n",
      "Epoch 1/50\n",
      "Train Loss: 0.6539, Train Accuracy: 0.6220\n",
      "Val Loss: 0.6602, Val Accuracy: 0.6062\n",
      "Patience Counter: 0/5\n",
      "--------------------\n",
      "Epoch 2/50\n",
      "Train Loss: 0.6430, Train Accuracy: 0.6310\n",
      "Val Loss: 0.6601, Val Accuracy: 0.6066\n",
      "Patience Counter: 0/5\n",
      "--------------------\n",
      "Epoch 3/50\n",
      "Train Loss: 0.6411, Train Accuracy: 0.6342\n",
      "Val Loss: 0.6583, Val Accuracy: 0.6038\n",
      "Patience Counter: 0/5\n",
      "--------------------\n",
      "Epoch 4/50\n",
      "Train Loss: 0.6402, Train Accuracy: 0.6376\n",
      "Val Loss: 0.6602, Val Accuracy: 0.6059\n",
      "Patience Counter: 1/5\n",
      "--------------------\n",
      "Epoch 5/50\n",
      "Train Loss: 0.6400, Train Accuracy: 0.6370\n",
      "Val Loss: 0.6579, Val Accuracy: 0.6080\n",
      "Patience Counter: 0/5\n",
      "--------------------\n",
      "Epoch 6/50\n",
      "Train Loss: 0.6393, Train Accuracy: 0.6371\n",
      "Val Loss: 0.6611, Val Accuracy: 0.6035\n",
      "Patience Counter: 1/5\n",
      "--------------------\n",
      "Epoch 7/50\n",
      "Train Loss: 0.6391, Train Accuracy: 0.6372\n",
      "Val Loss: 0.6589, Val Accuracy: 0.6021\n",
      "Patience Counter: 2/5\n",
      "--------------------\n",
      "Epoch 8/50\n",
      "Train Loss: 0.6381, Train Accuracy: 0.6381\n",
      "Val Loss: 0.6588, Val Accuracy: 0.6042\n",
      "Patience Counter: 3/5\n",
      "--------------------\n",
      "Epoch 9/50\n",
      "Train Loss: 0.6373, Train Accuracy: 0.6390\n",
      "Val Loss: 0.6576, Val Accuracy: 0.6073\n",
      "Patience Counter: 0/5\n",
      "--------------------\n",
      "Epoch 10/50\n",
      "Train Loss: 0.6368, Train Accuracy: 0.6398\n",
      "Val Loss: 0.6583, Val Accuracy: 0.6076\n",
      "Patience Counter: 1/5\n",
      "--------------------\n",
      "Epoch 11/50\n",
      "Train Loss: 0.6362, Train Accuracy: 0.6411\n",
      "Val Loss: 0.6581, Val Accuracy: 0.6087\n",
      "Patience Counter: 2/5\n",
      "--------------------\n",
      "Epoch 12/50\n",
      "Train Loss: 0.6363, Train Accuracy: 0.6413\n",
      "Val Loss: 0.6602, Val Accuracy: 0.6028\n",
      "Patience Counter: 3/5\n",
      "--------------------\n",
      "Epoch 13/50\n",
      "Train Loss: 0.6352, Train Accuracy: 0.6436\n",
      "Val Loss: 0.6608, Val Accuracy: 0.6045\n",
      "Patience Counter: 4/5\n",
      "--------------------\n",
      "Epoch 14/50\n",
      "Train Loss: 0.6350, Train Accuracy: 0.6428\n",
      "Val Loss: 0.6631, Val Accuracy: 0.6076\n",
      "Patience Counter: 5/5\n",
      "--------------------\n",
      "Early stopping triggered after epoch 14\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('processed_game_objects.pkl', 'rb') as f:\n",
    "    processed_data = pickle.load(f)\n",
    "\n",
    "features = [\n",
    "    'days_ago', \n",
    "    'games_ago', \n",
    "    'is_home_team', \n",
    "    'is_regular_season_matchup', \n",
    "    'is_playoffs_matchup', \n",
    "    'is_pre_season_matchup', \n",
    "    'wl', \n",
    "    'pts_for', \n",
    "    'fg_pct_for', \n",
    "    'fg3_pct_for', \n",
    "    'fg3m_for', \n",
    "    'ft_pct_for', \n",
    "    'ftm_for', \n",
    "    'reb_for', \n",
    "    'ast_for', \n",
    "    'stl_for', \n",
    "    'blk_for', \n",
    "    'tov_for', \n",
    "    'pts_against', \n",
    "    'fg_pct_against', \n",
    "    'fg3_pct_against', \n",
    "    'fg3m_against', \n",
    "    'ft_pct_against', \n",
    "    'ftm_against', \n",
    "    'reb_against', \n",
    "    'ast_against', \n",
    "    'stl_against', \n",
    "    'blk_against', \n",
    "    'tov_against'\n",
    "    ]\n",
    "\n",
    "train_loader = create_feature_filtered_loader(train_loader, features, batch_size=32)\n",
    "val_loader = create_feature_filtered_loader(val_loader, features, batch_size=32)\n",
    "\n",
    "# Create and train model\n",
    "model = PredictorRNN(feature_names=features)\n",
    "trained_model, history = model.train_model(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 0 games with NaN values\n",
      "Remaining games: 2881\n",
      "\n",
      "Test Results:\n",
      "Total Test Games: 2881\n",
      "Correct Predictions: 1731\n",
      "Test Accuracy: 0.6008\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_predictions_raw = []  # Store raw probabilities\n",
    "    all_predictions = []      # Store binary predictions\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            outputs = model(batch)\n",
    "            target = batch['target'].view(-1, 1)\n",
    "\n",
    "            # Store raw probabilities\n",
    "            all_predictions_raw.extend(outputs.cpu().numpy().flatten())\n",
    "\n",
    "            # Get binary predictions\n",
    "            predictions = (outputs >= 0.5).float()\n",
    "            all_predictions.extend(predictions.cpu().numpy().flatten())\n",
    "            all_targets.extend(target.cpu().numpy().flatten())\n",
    "\n",
    "    # Convert to numpy arrays for easier manipulation\n",
    "    predictions_raw = np.array(all_predictions_raw)\n",
    "    predictions = np.array(all_predictions)\n",
    "    targets = np.array(all_targets)\n",
    "\n",
    "    # Calculate metrics\n",
    "    cm = confusion_matrix(targets, predictions)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    # Create figure with subplots\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "    # 1. Confusion Matrix\n",
    "    ax1 = fig.add_subplot(221)\n",
    "    im = ax1.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    ax1.set_title('Confusion Matrix')\n",
    "\n",
    "    # Add numbers to confusion matrix\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax1.text(j, i, str(cm[i, j]),\n",
    "                    ha=\"center\", va=\"center\", color=\"white\" if cm[i, j] > cm.max()/2 else \"black\")\n",
    "\n",
    "    plt.colorbar(im, ax=ax1)\n",
    "    ax1.set_xlabel('Predicted Label')\n",
    "    ax1.set_ylabel('True Label')\n",
    "    ax1.set_xticks([0, 1])\n",
    "    ax1.set_yticks([0, 1])\n",
    "    ax1.set_xticklabels(['0', '1'])\n",
    "    ax1.set_yticklabels(['0', '1'])\n",
    "\n",
    "    # 2. ROC Curve\n",
    "    ax2 = fig.add_subplot(222)\n",
    "    fpr, tpr, _ = roc_curve(targets, predictions_raw)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    ax2.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    ax2.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    ax2.set_xlim([0.0, 1.0])\n",
    "    ax2.set_ylim([0.0, 1.05])\n",
    "    ax2.set_xlabel('False Positive Rate')\n",
    "    ax2.set_ylabel('True Positive Rate')\n",
    "    ax2.set_title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    ax2.legend(loc=\"lower right\")\n",
    "    ax2.grid(True)\n",
    "\n",
    "    # 3. Precision-Recall Curve\n",
    "    ax3 = fig.add_subplot(223)\n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(targets, predictions_raw)\n",
    "    avg_precision = average_precision_score(targets, predictions_raw)\n",
    "\n",
    "    ax3.plot(recall_curve, precision_curve, color='blue', lw=2,\n",
    "             label=f'Precision-Recall curve (AP = {avg_precision:.2f})')\n",
    "    ax3.set_xlabel('Recall')\n",
    "    ax3.set_ylabel('Precision')\n",
    "    ax3.set_title('Precision-Recall Curve')\n",
    "    ax3.legend(loc=\"lower left\")\n",
    "    ax3.grid(True)\n",
    "\n",
    "    # 4. Prediction Distribution\n",
    "    ax4 = fig.add_subplot(224)\n",
    "    ax4.hist(predictions_raw, bins=50, alpha=0.5, label='All Predictions')\n",
    "    ax4.hist(predictions_raw[targets == 1], bins=50, alpha=0.5, label='Actual Positive')\n",
    "    ax4.hist(predictions_raw[targets == 0], bins=50, alpha=0.5, label='Actual Negative')\n",
    "    ax4.set_xlabel('Predicted Probability')\n",
    "    ax4.set_ylabel('Count')\n",
    "    ax4.set_title('Distribution of Predictions')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('evaluation_metrics.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"\\nModel Evaluation Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(f\"True Negatives: {tn}\")\n",
    "    print(f\"False Positives: {fp}\")\n",
    "    print(f\"False Negatives: {fn}\")\n",
    "    print(f\"True Positives: {tp}\")\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'roc_auc': roc_auc,\n",
    "        'avg_precision': avg_precision,\n",
    "        'confusion_matrix': cm,\n",
    "        'predictions_raw': predictions_raw,\n",
    "        'predictions': predictions,\n",
    "        'targets': targets\n",
    "    }\n",
    "\n",
    "# Usage:\n",
    "test_loader = create_feature_filtered_loader(test_loader, features, batch_size=32)\n",
    "metrics = evaluate_model(trained_model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
